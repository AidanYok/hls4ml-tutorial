{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Choose the target board. You may need to install the proper board files for the chosen board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ZCU106\n",
    "#board_name='zcu106'\n",
    "#fpga_part='xczu7ev-ffvc1156-2-e'\n",
    " \n",
    "## Ultra96\n",
    "#board_name='ultra96'\n",
    "#fpga_part='xczu3eg-sbva484-1-e'\n",
    "\n",
    "## Pynq-Z1\n",
    "board_name='pynqz1'\n",
    "fpga_part='xc7z020clg400-1'\n",
    "\n",
    "## Pynq-Z2\n",
    "#board_name='pynqz2'\n",
    "#fpga_part='xc7z020clg400-1'\n",
    "\n",
    "## MiniZed\n",
    "#board_name='minized'\n",
    "#fpga_part='xc7z007sclg225-1'\n",
    "\n",
    "##Cmod A7-35t\n",
    "#board_name='cmoda735t'\n",
    "#fpga_part='xc7a35tcpg236-1'\n",
    "\n",
    "## Arty A7-100t\n",
    "#board_name='artya7100t'\n",
    "#fpga_part='xc7a100t-csg324-1'\n",
    "\n",
    "## Arty A7-35t\n",
    "#board_name='artya735t'\n",
    "#fpga_part='xc7a35ticsg324-1L'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the project name. The notebook will create sub-directories for the Vivado projects with different models and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_name='resnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the libraries, call the magic functions, and setup the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import hls4ml\n",
    "\n",
    "from callbacks import all_callbacks\n",
    "import plotting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['PATH'] = '/tools/Xilinx/Vivado/2019.1/bin:' + os.environ['PATH']\n",
    "\n",
    "def is_tool(name):\n",
    "    from distutils.spawn import find_executable\n",
    "    return find_executable(name) is not None\n",
    "\n",
    "print('-----------------------------------')\n",
    "if not is_tool('vivado_hls'):\n",
    "    print('Xilinx Vivado HLS is NOT in the PATH')\n",
    "else:\n",
    "    print('Xilinx Vivado HLS is in the PATH')\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load processed test data\n",
    "from sklearn.utils import shuffle\n",
    "X_test = np.load('./test_data/resnet/X_test.npy', allow_pickle=True)\n",
    "y_test = np.load('./test_data/resnet/y_test.npy', allow_pickle=True) # ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train or Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras_model\n",
    "train = False\n",
    "#not os.path.exists('model/KERAS_check_best_model.h5')\n",
    "if train:\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "        \n",
    "    print(\"Shape of training data element is: {}\".format(train_data[0].shape))\n",
    "    history = model.fit(train_data,\n",
    "                        train_data,\n",
    "                        epochs=100,\n",
    "                        batch_size=512,\n",
    "                        shuffle=true,\n",
    "                        validation_split=0.1,\n",
    "                        verbose=1,\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "\n",
    "else:\n",
    "    #model_file = \"model/resnet/model_best_20210424.h5\"\n",
    "    \n",
    "    # RN03\n",
    "    #model_file = 'model/resnet/rn03/myquant.h5'\n",
    "    #model_file = 'model/resnet/rn03/myquant_nosoftmax.h5'\n",
    "    \n",
    "    # RN06\n",
    "    model_file = 'model/resnet/rn06/rushil2_nosoftmax.h5'\n",
    "    \n",
    "    if not os.path.exists(model_file):\n",
    "        print(\"{} model not found at path \".format(model_file))\n",
    "\n",
    "    model = keras_model.load_model(model_file)\n",
    "\n",
    "model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select a portion of the model to debug**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input_layer = None\n",
    "output_layer = None\n",
    "\n",
    "for layer in model.layers:\n",
    "    if layer.name=='input_1': \n",
    "        input_layer = layer.input\n",
    "    if layer.name=='q_conv2d_batchnorm_2':\n",
    "        output_layer = layer.output\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "input_layer = None\n",
    "output_layer = None\n",
    "\n",
    "for layer in model.layers:\n",
    "    if layer.name=='q_conv2d_batchnorm_2':\n",
    "        input_layer = Input(layer.input.shape[1:])\n",
    "        output_layer = layer(input_layer)\n",
    "        break\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Do not forget to append only the layers that appear in the \"smaller\" model\n",
    "keys = []\n",
    "#keys.append('input_1')\n",
    "#keys.append('q_conv2d_batchnorm')\n",
    "#keys.append('q_activation')\n",
    "#keys.append('q_conv2d_batchnorm_1')\n",
    "#keys.append('q_activation_1')\n",
    "keys.append('q_conv2d_batchnorm_2')\n",
    "#keys.append('q_activation_2')\n",
    "#keys.append('average_pooling2d')\n",
    "#keys.append('q_activation_3')\n",
    "#keys.append('flatten')\n",
    "#keys.append('q_dense')\n",
    "#keys.append('softmax')\n",
    "\n",
    "override_keys = []\n",
    "#override_keys.append('input_1')\n",
    "#override_keys.append('q_conv2d_batchnorm')\n",
    "#override_keys.append('q_conv2d_batchnorm_1')\n",
    "override_keys.append('q_conv2d_batchnorm_2')\n",
    "#override_keys.append('average_pooling2d')\n",
    "#override_keys.append('q_dense')\n",
    "#override_keys.append('softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model sparisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.layers[1].weights[0].numpy()\n",
    "h, b = np.histogram(w, bins=100)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.bar(b[:-1], h, width=b[1]-b[0])\n",
    "plt.semilogy()\n",
    "print('% of zeros = {}'.format(np.sum(w==0)/np.size(w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check accuracy\n",
    "\n",
    "Do not expect a good accuracy because of the low amount of neurons. I could have done better than this, but as long as it fits both Pynq-Z1 and MiniZed, it is fine with us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotting\n",
    "\n",
    "y_keras = model.predict(X_test)\n",
    "\n",
    "classes = ['airplanes', 'cars', 'birds', 'cats', 'deer', 'dogs', 'frogs', 'horses', 'ships', 'trucks']\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "_ = plotting.plotMultiClassRoc(y_test, y_keras, classes)\n",
    "\n",
    "import plotting # Import local package plotting.py\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true=np.argmax(y_test, axis=1), y_pred=np.argmax(y_keras, axis=1))\n",
    "plt.figure(figsize=(9,9))\n",
    "_ = plotting.plot_confusion_matrix(cm, classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an hls4ml configuration\n",
    "\n",
    "Notice we're using `Strategy: Resource` for every layer, and `ReuseFactor: 64`. The Programmable Logic (FPGA part) of the Pynq-Z1 SoC is not big compared to VU9P type of parts.\n",
    "\n",
    "We also use some settings which are good for QKeras.\n",
    "\n",
    "Notice the `fpga_part:'xc7z020clg400-1'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def yaml_load(config):\n",
    "    with open(config) as stream:\n",
    "        param = yaml.safe_load(stream)\n",
    "    return param\n",
    "\n",
    "\n",
    "#training_config = yaml_load('model/resnet/config_20210424.yml')\n",
    "\n",
    "# RN03\n",
    "#training_config = yaml_load('model/resnet/rn03/myquant.yml')\n",
    "\n",
    "# RN06\n",
    "training_config = yaml_load('model/resnet/rn06/rushil2.yml')\n",
    "\n",
    "\n",
    "# print(\"-----------------------------------\")\n",
    "#plotting.print_dict(training_config)\n",
    "# print(\"-----------------------------------\")\n",
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "hls_config['Model'] = {}\n",
    "hls_config['Model']['ReuseFactor'] = training_config['convert']['ReuseFactor']\n",
    "hls_config['Model']['Strategy'] = training_config['convert']['Strategy']\n",
    "hls_config['Model']['Precision'] = training_config['convert']['Precision']\n",
    "\n",
    "## DEBUG DEBUG DEBUG\n",
    "##\n",
    "## arrays keys and override_kets have been previously defined\n",
    "## \n",
    "#for name in keys:\n",
    "#    hls_config['LayerName'][name]['Trace'] = bool(training_config['convert']['Trace'])\n",
    "#    hls_config['LayerName'][name]['ReuseFactor'] = training_config['convert']['ReuseFactor']\n",
    "#    hls_config['LayerName'][name]['Precision'] = training_config['convert']['Precision']\n",
    "#    if 'activation' in name:\n",
    "#        hls_config['LayerName'][name]['Precision'] = training_config['convert']['PrecisionActivation']\n",
    "## custom configs\n",
    "#for name in override_keys:\n",
    "#    hls_config['LayerName'][name].update(training_config['convert']['Override'][name])\n",
    "## DEBUG DEBUG DEBUG\n",
    "\n",
    "\n",
    "# THE ORIGINAL CONFIGURATION\n",
    "for name in hls_config['LayerName'].keys():\n",
    "    hls_config['LayerName'][name]['Trace'] = bool(training_config['convert']['Trace'])\n",
    "    hls_config['LayerName'][name]['ReuseFactor'] = training_config['convert']['ReuseFactor']\n",
    "    hls_config['LayerName'][name]['Precision'] = training_config['convert']['Precision']\n",
    "    if 'activation' in name:\n",
    "        hls_config['LayerName'][name]['Precision'] = training_config['convert']['PrecisionActivation']\n",
    "# custom configs\n",
    "for name in training_config['convert']['Override'].keys():\n",
    "    hls_config['LayerName'][name].update(training_config['convert']['Override'][name])\n",
    "\n",
    "# Enable tracing for all of the layers\n",
    "for layer in hls_config['LayerName'].keys():\n",
    "    hls_config['LayerName'][layer]['Trace'] = True\n",
    "    \n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(hls_config)\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert and Compile\n",
    "\n",
    "You can set some target specific configurations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define the `interface`, which for our current setup should always be `m_axi`.\n",
    "- Define the  width of the AXI bus. For the time being, use `16` that is each clock cycle you transfer a single input or output value (`ap_fixed<16,*>`).\n",
    "- Define the implementation. For the time being, use `serial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = 'm_axi' # 's_axilite', 'm_axi', 'io_stream'\n",
    "axi_width = 8 # 16, 32, 64\n",
    "implementation = 'serial' # 'serial', 'dataflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#output_dir='hls/' + '256x16x8x256_' + '_' + interface + '_' + str(axi_width) + '_' + implementation + '_prj'\n",
    "output_dir='hls/' + board_name + '_' + acc_name + '_' + interface + '_' + str(axi_width) + '_' + implementation + '_prj' \n",
    "\n",
    "backend_config = hls4ml.converters.create_backend_config(fpga_part=fpga_part)\n",
    "backend_config['ProjectName'] = acc_name\n",
    "backend_config['KerasModel'] = model\n",
    "backend_config['HLSConfig'] = hls_config\n",
    "backend_config['OutputDir'] = output_dir\n",
    "backend_config['Backend'] = 'Pynq'\n",
    "backend_config['Interface'] = interface\n",
    "backend_config['IOType'] = 'io_stream'\n",
    "backend_config['AxiWidth'] = str(axi_width)\n",
    "backend_config['Implementation'] = implementation\n",
    "backend_config['ClockPeriod'] = 10\n",
    "\n",
    "#print(\"-----------------------------------\")\n",
    "#plotting.print_dict(backend_config)\n",
    "#print(\"-----------------------------------\")\n",
    "\n",
    "hls_model = hls4ml.converters.keras_to_hls(backend_config)\n",
    "# hls_model = hls4ml.converters.convert_from_keras_model(model,\n",
    "#                                                                 hls_config=hls_config,\n",
    "#                                                                 output_dir=output_dir,\n",
    "#                                                                 fpga_part=fpga_part,\n",
    "#                                                                 clock_period=10,\n",
    "#                                                                 io_type='io_parallel',\n",
    "#                                                                 project_name='anomaly_detector')\n",
    "\n",
    "_ = hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "# Run tracing on the test set for the hls model (fixed-point precision) \n",
    "hls4ml_pred, hls4ml_trace = hls_model.trace(np.ascontiguousarray(X_test))\n",
    "\n",
    "# Run tracing on the test set for the Keras model (floating-point precision)\n",
    "keras_trace = hls4ml.model.profiling.get_ymodel_keras(model, X_test)\n",
    "\n",
    "# Run prediction on the test set for the hls model (fixed-point precision)\n",
    "y_hls = hls_model.predict(np.ascontiguousarray(X_test))\n",
    "\n",
    "_ = hls4ml.model.profiling.numerical(model=model, hls_model=hls_model, X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just print the output of the first layer, for the first sample, for both the Keras and hls4ml models."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# print('-----------------------------------')\n",
    "# print(\"Keras layer 'q_conv2d_batchnorm', first sample:\")\n",
    "# print(keras_trace['q_conv2d_batchnorm'][0])\n",
    "# print('-----------------------------------')\n",
    "# print(\"hls4ml layer 'q_conv2d_batchnorm', first sample:\")\n",
    "# print(hls4ml_trace['q_conv2d_batchnorm'][0])\n",
    "# print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Edits\n",
    "\n",
    "Edit the following files:\n",
    "- resnet_test.cpp\n",
    "- firmware/resnet_axi.h\n",
    "\n",
    "```\n",
    "cd hls/pynqz1_resnet_m_axi_8_serial_prj\n",
    "cp ../../patches/resnet/resnet_test.cpp ./resnet_test.cpp\n",
    "cp ../../patches/resnet/resnet_axi.h ./firmware/resnet_axi.h\n",
    "```\n",
    "\n",
    "If you want to use 8-bit integer inputs, edit the following files instead:\n",
    "```\n",
    "cd hls/pynqz1_resnet_m_axi_8_serial_prj\n",
    "cp ../../patches/resnet_div256/resnet_test.cpp ./resnet_test.cpp\n",
    "cp ../../patches/resnet_div256/resnet_axi.h ./firmware/resnet_axi.h\n",
    "cp ../../patches/resnet_div256/resnet_axi.h ./firmware/resnet_axi.h\n",
    "```\n",
    "\n",
    "### Run Vivado HLS c-sim for Integrity Test\n",
    "\n",
    "Edit `build_prj.tcl`\n",
    "\n",
    "```\n",
    "array set opt {\n",
    "  reset      0\n",
    "  csim       1\n",
    "  synth      0\n",
    "  cosim      0\n",
    "  validation 0\n",
    "  export     0\n",
    "  vsynth     0\n",
    "} \n",
    "```\n",
    "\n",
    "Then \n",
    "```\n",
    "$ vivado_hls -f build_prj.tcl\n",
    "```\n",
    "\n",
    "### Generate .so Library\n",
    "\n",
    "```\n",
    "$ rm firmware/resnet-*.so \n",
    "$ bash build_lib.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----------------------------------')\n",
    "print(\"Keras  Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "print(\"hls4ml Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls, axis=1))))\n",
    "print('-----------------------------------')\n",
    "\n",
    "# Enable logarithmic scale on TPR and FPR axes \n",
    "logscale_tpr = False # Y axis\n",
    "logscale_fpr = False # X axis\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "_ = plotting.plotMultiClassRoc(y_test, y_keras, classes, logscale_tpr=logscale_tpr, logscale_fpr=logscale_fpr)\n",
    "plt.gca().set_prop_cycle(None) # reset the colors\n",
    "_ = plotting.plotMultiClassRoc(y_test, y_hls, classes, logscale_tpr=logscale_tpr, logscale_fpr=logscale_fpr, linestyle='--')\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "lines = [Line2D([0], [0], ls='-'),\n",
    "         Line2D([0], [0], ls='--')]\n",
    "from matplotlib.legend import Legend\n",
    "leg = Legend(ax, lines, labels=['keras', 'hls4ml'],\n",
    "            loc='center right', frameon=False)\n",
    "_ = ax.add_artist(leg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build(csim=False, synth=True, export=True, vsynth=False)\n",
    "\n",
    "hls4ml.report.read_vivado_report(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource Reference\n",
    "\n",
    "See the resources availables on different boards.\n",
    "\n",
    "```\n",
    "+-----------------+---------+-------+--------+-------+-----+                    \n",
    "|                 |               Resource                 |\n",
    "+-----------------+---------+-------+--------+-------+-----+\n",
    "|      Board      | BRAM_18K| DSP48E|   FF   |  LUT  | URAM|\n",
    "+-----------------+---------+-------+--------+-------+-----+\n",
    "|   PYNQ-Z1/Z2    |      280|    220|  106400|  53200|    0|\n",
    "+-----------------+---------+-------+--------+-------+-----+\n",
    "|     MiniZed     |      100|     66|   28800|  14400|    0|\n",
    "+-----------------+---------+-------+--------+-------+-----+\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate .dat Files (Step 3)\n",
    "\n",
    "The .dat files are used\n",
    "- during the following `csim` step\n",
    "- to generate the header files for SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(output_dir + '/tb_data/tb_input_features.dat', 'w')\n",
    "# Save the first N images\n",
    "N=10\n",
    "for i in range(N):\n",
    "    for j in range(X_test.shape[1]):\n",
    "        for k in range(X_test.shape[2]):\n",
    "            for c in range(X_test.shape[3]):\n",
    "                f.write('{} '.format(X_test[i][j][k][c]))\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "f = open(output_dir + '/tb_data/tb_output_predictions.dat', 'w')\n",
    "for i in range(N):\n",
    "    for j in range(y_test.shape[1]):\n",
    "        f.write('{} '.format(y_test[i][j]))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Vivado HLS csim\n",
    "\n",
    "At this step we generate simulation traces out from the hls4ml-model.\n",
    "\n",
    "Run the following cell to run Vivado HLS GUI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cd $output_dir && vivado_hls -p $acc_name\\_prj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**  Click the button to `Run C Simulation`.\n",
    "\n",
    "This will generate simulation traces with fixed-point arythmetic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate IP in a Vivado Project and Generate Bitstream (Step 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd sys/$board_name && make clean sys-gui ACC=$acc_name INTERFACE=$interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Tell the user how to visualize the `Block Diagram` to get a better understanding of the IP integration with both Zynq and MicroBlaze PS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Software in Vivado SDK and Run HW/SW on the Board (Step 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Vivado SDK project.\n",
    "\n",
    "- `make sdk` to configure an application with register polling\n",
    "- `make sdk-irq` to configure an application with interrupts (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /tools/Xilinx/Vivado/2019.1/settings64.sh && cd sdk/$board_name && make clean sdk ACC=$acc_name SAMPLE_COUNT=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xterm -e \"sleep 1 && source /tools/Xilinx/Vivado/2019.1/settings64.sh && cd sdk/$board_name && make gui && sleep infinity\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can open a serial console, for example\n",
    "```\n",
    "sudo minicom -D /dev/ttyUSB0\n",
    "```\n",
    "and see something like\n",
    "\n",
    "![serial-console](doc/serial_console.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
