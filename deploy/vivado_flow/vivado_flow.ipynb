{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Choose the target board. For the time being, you can use `minized`, `pynqz1`, `pynqz2`, `cmoda735t`. You may need to install the proper board files for the chosen board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ZCU106\n",
    "#board_name='zcu106'\n",
    "#fpga_part='xczu7ev-ffvc1156-2-e'\n",
    " \n",
    "## Ultra96\n",
    "#board_name='ultra96'\n",
    "#fpga_part='xczu3eg-sbva484-1-e'\n",
    "\n",
    "## Pynq-Z1\n",
    "board_name='pynqz1'\n",
    "fpga_part='xc7z020clg400-1'\n",
    "\n",
    "## Pynq-Z2\n",
    "#board_name='pynqz2'\n",
    "#fpga_part='xc7z020clg400-1'\n",
    "\n",
    "## MiniZed\n",
    "#board_name='minized'\n",
    "#fpga_part='xc7z007sclg225-1'\n",
    "\n",
    "##Cmod A7-35t\n",
    "#board_name='cmoda735t'\n",
    "#fpga_part='xc7a35tcpg236-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the libraries, call the magic functions, and setup the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import hls4ml\n",
    "\n",
    "from callbacks import all_callbacks\n",
    "import plotting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['PATH'] = '/tools/Xilinx/Vivado/2019.1/bin:' + os.environ['PATH']\n",
    "\n",
    "def is_tool(name):\n",
    "    from distutils.spawn import find_executable\n",
    "    return find_executable(name) is not None\n",
    "\n",
    "print('-----------------------------------')\n",
    "if not is_tool('vivado_hls'):\n",
    "    print('Xilinx Vivado HLS is NOT in the PATH')\n",
    "else:\n",
    "    print('Xilinx Vivado HLS is in the PATH')\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "This is a lot like the previous notebooks, so we will go through quickly.\n",
    "\n",
    "First, we fetch the dataset from file, do the normalization and make a train and test split.\n",
    "\n",
    "We save the test dataset to files so that we can use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load processed test data\n",
    "from sklearn.utils import shuffle\n",
    "X = np.load('./test_data/test_data_frames_4_hops_512_fft_1024_mels_64_power_2.0.npy', allow_pickle=True)\n",
    "y = np.load('./test_data/test_data_frames_4_hops_512_fft_1024_mels_64_power_2.0_ground_truths.npy', allow_pickle=True)\n",
    "y_keras = []\n",
    "#use a quarter of the test_set to save time\n",
    "for i in range(len(X)):\n",
    "    quarter = int(len(X[i])/4)\n",
    "    assert len(X) == len(y)\n",
    "    #X[i], y[i] = shuffle(X[i], y[i])\n",
    "    X[i], y[i] = X[i][0:quarter],  y[i][0:quarter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train or Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras_model\n",
    "train = False\n",
    "#not os.path.exists('model/KERAS_check_best_model.h5')\n",
    "if train:\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "        \n",
    "    print(\"Shape of training data element is: {}\".format(train_data[0].shape))\n",
    "    history = model.fit(train_data,\n",
    "                        train_data,\n",
    "                        epochs=100,\n",
    "                        batch_size=512,\n",
    "                        shuffle=true,\n",
    "                        validation_split=0.1,\n",
    "                        verbose=1,\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "\n",
    "else:\n",
    "    #model_file = 'model/train_config_bits_6_frames_4_mels_64_hidDims_64_encDims_8_bn_True_l1reg0/model_ToyCar.h5'\n",
    "    model_file = \"model/tiny_qkeras_model/train_config_bits_6_frames_4_mels_64_encDims_8_hidDims_64_bn_True_qbatch_False_l1reg_0/model_ToyCar.h5\"\n",
    "    if not os.path.exists(model_file):\n",
    "        print(\"{} model not found at path \".format(model_file))\n",
    "\n",
    "    model = keras_model.load_model(model_file)\n",
    "\n",
    "model.summary()    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input_layer = None\n",
    "output_layer = None\n",
    "\n",
    "for layer in model.layers:\n",
    "    if layer.name=='q_dense': \n",
    "        input_layer = layer.input\n",
    "    if layer.name=='q_activation':\n",
    "        output_layer = layer.output\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model sparisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.layers[1].weights[0].numpy()\n",
    "h, b = np.histogram(w, bins=100)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.bar(b[:-1], h, width=b[1]-b[0])\n",
    "plt.semilogy()\n",
    "print('% of zeros = {}'.format(np.sum(w==0)/np.size(w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check accuracy\n",
    "\n",
    "Do not expect a good accuracy because of the low amount of neurons. I could have done better than this, but as long as it fits both Pynq-Z1 and MiniZed, it is fine with us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotting\n",
    "import numpy\n",
    "\n",
    "#load processed test data\n",
    "X = np.load('./test_data/test_data_frames_4_hops_512_fft_1024_mels_64_power_2.0.npy', allow_pickle=True)\n",
    "y = np.load('./test_data/test_data_frames_4_hops_512_fft_1024_mels_64_power_2.0_ground_truths.npy', allow_pickle=True)\n",
    "y_keras = []\n",
    "#use a quarter of the test_set to save time\n",
    "for i in range(len(X)):\n",
    "    quarter = int(len(X[i])/4)\n",
    "    assert len(X) == len(y)\n",
    "    X[i], y[i] = shuffle(X[i], y[i])\n",
    "    X[i], y[i] = X[i][0:quarter],  y[i][0:quarter]\n",
    "\n",
    "#perform inference\n",
    "for index, X_data in enumerate(X):\n",
    "    y_pred = [0. for ind in X_data]\n",
    "    for file_idx, X_test in enumerate(X_data):\n",
    "        predictions = model.predict(X_test)\n",
    "        errors = np.mean(np.square(X_test-predictions), axis=1)\n",
    "        y_pred[file_idx] = numpy.mean(errors)\n",
    "        \n",
    "    #generate auc and roc metrics\n",
    "    y_test = y[index]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    y_keras.append(y_pred)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, label = 'AUC m_{} = {}'.format(index, round(roc_auc,2)), linewidth = 1.5)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--', linewidth=1)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an hls4ml configuration (Step 2)\n",
    "\n",
    "Notice we're using `Strategy: Resource` for every layer, and `ReuseFactor: 64`. The Programmable Logic (FPGA part) of the Pynq-Z1 SoC is not big compared to VU9P type of parts.\n",
    "\n",
    "We also use some settings which are good for QKeras.\n",
    "\n",
    "Notice the `fpga_part:'xc7z020clg400-1'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "hls_config['Model'] = {}\n",
    "hls_config['Model']['ReuseFactor'] = 1024\n",
    "hls_config['Model']['Strategy'] = 'Resource'\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<32,16>'\n",
    "hls_config['LayerName']['input_1']['Precision'] = 'ap_fixed<8,8>'\n",
    "\n",
    "hls_config['LayerName']['q_dense']['Precision']['weight'] = 'ap_fixed<7,1>'\n",
    "hls_config['LayerName']['q_dense']['Precision']['bias'] = 'ap_fixed<7,1>'\n",
    "hls_config['LayerName']['q_dense']['accum_t'] = 'ap_fixed<32,16>'\n",
    "hls_config['LayerName']['q_dense']['ReuseFactor'] = 1024\n",
    "\n",
    "hls_config['LayerName']['batch_normalization']['Precision']['scale'] = 'ap_fixed<16,6>'\n",
    "hls_config['LayerName']['batch_normalization']['Precision']['bias'] = 'ap_fixed<16,6>'\n",
    "hls_config['LayerName']['batch_normalization']['ReuseFactor'] = 1024\n",
    "\n",
    "hls_config['LayerName']['q_activation']['Precision']['result'] = 'ap_fixed<7,4>'\n",
    "hls_config['LayerName']['q_activation']['ReuseFactor'] = 1024\n",
    "\n",
    "for i in range(1,2):\n",
    "    \n",
    "    hls_config['LayerName']['q_dense_{}'.format(i)]['Precision']['weight'] = 'ap_fixed<7,1>'\n",
    "    hls_config['LayerName']['q_dense_{}'.format(i)]['Precision']['bias'] = 'ap_fixed<7,1>'\n",
    "    hls_config['LayerName']['q_dense_{}'.format(i)]['ReuseFactor'] = 1024\n",
    "    hls_config['LayerName']['q_dense_{}'.format(i)]['accum_t'] = 'ap_fixed<32,16>'\n",
    "\n",
    "    hls_config['LayerName']['batch_normalization_{}'.format(i)]['Precision']['scale'] = 'ap_fixed<16,6>'\n",
    "    hls_config['LayerName']['batch_normalization_{}'.format(i)]['Precision']['bias'] = 'ap_fixed<16,6>'\n",
    "    hls_config['LayerName']['batch_normalization_{}'.format(i)]['ReuseFactor'] =1024\n",
    "\n",
    "    hls_config['LayerName']['q_activation_{}'.format(i)]['Precision']['result'] = 'ap_fixed<7,4>'\n",
    "    hls_config['LayerName']['q_activation_{}'.format(i)]['ReuseFactor'] = 1024\n",
    "    \n",
    "# Final output\n",
    "hls_config['LayerName']['q_dense_2']['Precision']['weight'] = 'ap_fixed<7,7>'\n",
    "hls_config['LayerName']['q_dense_2']['Precision']['bias'] = 'ap_fixed<7,7>'\n",
    "hls_config['LayerName']['q_dense_2']['accum_t'] = 'ap_fixed<32,16>'\n",
    "hls_config['LayerName']['q_dense_2']['ReuseFactor'] = 1024\n",
    "\n",
    "# Enable tracing for all of the layers\n",
    "for layer in hls_config['LayerName'].keys():\n",
    "    hls_config['LayerName'][layer]['Trace'] = True\n",
    "\n",
    "# print(\"-----------------------------------\")\n",
    "plotting.print_dict(hls_config)\n",
    "# print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert and Compile\n",
    "\n",
    "You can set some target specific configurations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define the `interface`, which for our current setup should always be `m_axi`.\n",
    "- Define the  width of the AXI bus. For the time being, use `16` that is each clock cycle you transfer a single input or output value (`ap_fixed<16,*>`).\n",
    "- Define the implementation. For the time being, use `serial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = 'm_axi' # 's_axilite', 'm_axi', 'hls_stream'\n",
    "axi_width = 8 # 16, 32, 64\n",
    "implementation = 'serial' # 'serial', 'dataflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#output_dir='hls/' + '256x16x8x256_' + '_' + interface + '_' + str(axi_width) + '_' + implementation + '_prj'\n",
    "output_dir='hls/' + board_name + '_' + interface + '_' + str(axi_width) + '_' + implementation + '_prj' \n",
    "\n",
    "backend_config = hls4ml.converters.create_backend_config(fpga_part=fpga_part)\n",
    "backend_config['ProjectName'] = 'anomaly_detector'\n",
    "backend_config['KerasModel'] = model\n",
    "backend_config['HLSConfig'] = hls_config\n",
    "backend_config['OutputDir'] = output_dir\n",
    "backend_config['Backend'] = 'Pynq'\n",
    "backend_config['Interface'] = interface\n",
    "backend_config['IOType'] = 'io_parallel'\n",
    "backend_config['AxiWidth'] = str(axi_width)\n",
    "backend_config['Implementation'] = implementation\n",
    "backend_config['ClockPeriod'] = 10\n",
    "\n",
    "#print(\"-----------------------------------\")\n",
    "#plotting.print_dict(backend_config)\n",
    "#print(\"-----------------------------------\")\n",
    "\n",
    "hls_model = hls4ml.converters.keras_to_hls(backend_config)\n",
    "# hls_model = hls4ml.converters.convert_from_keras_model(model,\n",
    "#                                                                 hls_config=hls_config,\n",
    "#                                                                 output_dir=output_dir,\n",
    "#                                                                 fpga_part=fpga_part,\n",
    "#                                                                 clock_period=10,\n",
    "#                                                                 io_type='io_parallel',\n",
    "#                                                                 project_name='anomaly_detector')\n",
    "\n",
    "_ = hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "# Run tracing on a portion of the test set for the hls model (fixed-point precision) \n",
    "hls4ml_pred, hls4ml_trace = hls_model.trace(np.ascontiguousarray(X[0][0][0]))\n",
    "\n",
    "# Run tracing on a portion of the test set for the Keras model (floating-point precision)\n",
    "keras_trace = hls4ml.model.profiling.get_ymodel_keras(model, X[0][0])\n",
    "\n",
    "# Run prediction on a portion of the test set for the hls model (fixed-point precision)\n",
    "#y_hls = hls_model.predict(np.ascontiguousarray(X[0][0][0]))\n",
    "\n",
    "#_ = hls4ml.model.profiling.numerical(model=model, hls_model=hls_model, X=X[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just print the output of the first layer, for the first sample, for both the Keras and hls4ml models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----------------------------------')\n",
    "print(\"Keras layer 'q_dense', first sample:\")\n",
    "print(keras_trace['q_dense'][0])\n",
    "print('-----------------------------------')\n",
    "print(\"hls4ml layer 'q_dense', first sample:\")\n",
    "print(hls4ml_trace['q_dense'][0])\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load processed test data\n",
    "X = np.load('./test_data/test_data_frames_4_hops_512_fft_1024_mels_64_power_2.0.npy', allow_pickle=True)\n",
    "y = np.load('./test_data/test_data_frames_4_hops_512_fft_1024_mels_64_power_2.0_ground_truths.npy', allow_pickle=True)\n",
    "\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:purple']\n",
    "\n",
    "#use a quarter of the test_set to save time\n",
    "for i in range(len(X)):\n",
    "    quarter = int(len(X[i])/4)\n",
    "    assert len(X) == len(y)\n",
    "    X[i], y[i] = shuffle(X[i], y[i])\n",
    "    X[i], y[i] = X[i][0:quarter],  y[i][0:quarter]\n",
    "\n",
    "#perform inference\n",
    "for index, X_data in enumerate(X):\n",
    "    keras_pred = [0. for ind in X_data]\n",
    "    hls_pred = [0. for ind in X_data]\n",
    "    for file_idx, X_test in enumerate(X_data):\n",
    "        keras_predictions = model.predict(X_test)\n",
    "        keras_errors = np.mean(np.square(X_test-keras_predictions), axis=1)\n",
    "        keras_pred[file_idx] = numpy.mean(keras_errors)\n",
    "        \n",
    "        hls_predictions = hls_model.predict(X_test)\n",
    "        hls_errors = np.mean(np.square(X_test-hls_predictions), axis=1)\n",
    "        hls_pred[file_idx] = numpy.mean(hls_errors)\n",
    "        \n",
    "    #generate auc and roc metrics\n",
    "    y_test = y[index]\n",
    "    k_fpr, k_tpr, k_threshold = metrics.roc_curve(y_test, keras_pred)\n",
    "    k_roc_auc = metrics.auc(k_fpr, k_tpr)\n",
    "    h_fpr, h_tpr, h_threshold = metrics.roc_curve(y_test, hls_pred)\n",
    "    h_roc_auc = metrics.auc(h_fpr, h_tpr)\n",
    "\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(k_fpr, k_tpr, label = 'keras AUC m_{} = {}'.format(index, round(k_roc_auc,2)), linewidth = 1.5, color=colors[index])\n",
    "    plt.plot(h_fpr, h_tpr, label = 'hls AUC m_{} = {}'.format(index, round(h_roc_auc,2)), linewidth = 1, linestyle='--', color=colors[index])\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--', linewidth=1)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build(csim=False,synth=True,export=True, vsynth=False)\n",
    "\n",
    "hls4ml.report.read_vivado_report(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource Reference\n",
    "\n",
    "See the resources availables on different boards.\n",
    "\n",
    "```\n",
    "+-----------------+---------+-------+--------+-------+-----+                    \n",
    "|                 |               Resource                 |\n",
    "+-----------------+---------+-------+--------+-------+-----+\n",
    "|      Board      | BRAM_18K| DSP48E|   FF   |  LUT  | URAM|\n",
    "+-----------------+---------+-------+--------+-------+-----+\n",
    "|   PYNQ-Z1/Z2    |      280|    220|  106400|  53200|    0|\n",
    "+-----------------+---------+-------+--------+-------+-----+\n",
    "|     MiniZed     |      100|     66|   28800|  14400|    0|\n",
    "+-----------------+---------+-------+--------+-------+-----+\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate .dat Files (Step 3)\n",
    "\n",
    "The .dat files are used\n",
    "- during the following `csim` step\n",
    "- to generate the header files for SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X), len(X[0]), len(X[0][0]), len(X[0][0][0]))\n",
    "\n",
    "#print(y[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(output_dir + '/tb_data/tb_input_features.dat', 'w')\n",
    "\n",
    "# This is under the assumption that \n",
    "# 1. all the machines have the same number of wave files\n",
    "# 2. all of the wave files have the same number of frames\n",
    "# 3. all of the frames have the same length\n",
    "\n",
    "machine_count=len(X)\n",
    "wav_count=len(X[0])\n",
    "frame_count=len(X[0][0])\n",
    "frame_length=len(X[0][0][0])\n",
    "\n",
    "# Save the first N frames in the first wave file of the first machine\n",
    "N=10\n",
    "for i in range(N):\n",
    "    for j in range(frame_length):\n",
    "        f.write('{} '.format(X[0][0][i][j]))\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "f = open(output_dir + '/tb_data/tb_output_predictions.dat', 'w')\n",
    "for i in range(N):\n",
    "    f.write('{} '.format(y[0][i]))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Vivado HLS csim (Step 4)\n",
    "\n",
    "At this step we generate simulation traces out from the hls4ml-model.\n",
    "\n",
    "Run the following cell to run Vivado HLS GUI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd $output_dir && vivado_hls -p anomaly_detector_prj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT** Click the button to `Run C Simulation`.\n",
    "\n",
    "This will generate simulation traces with fixed-point arythmetic.\n",
    "\n",
    "When completed close Vivado HLS GUI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate IP in a Vivado Project and Generate Bitstream (Step 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd sys/$board_name && make clean sys-gui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Tell the user how to visualize the `Block Diagram` to get a better understanding of the IP integration with both Zynq and MicroBlaze PS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Software in Vivado SDK and Run HW/SW on the Board (Step 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Vivado SDK project.\n",
    "\n",
    "- `make sdk` to configure an application with register polling\n",
    "- `make sdk-irq` to configure an application with interrupts (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /tools/Xilinx/Vivado/2019.1/settings64.sh && cd sdk/$board_name && make clean sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xterm -e \"sleep 1 && source /tools/Xilinx/Vivado/2019.1/settings64.sh && cd sdk/$board_name && make gui && sleep infinity\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can open a serial console, for example\n",
    "```\n",
    "sudo minicom -D /dev/ttyUSB0\n",
    "```\n",
    "and see something like\n",
    "\n",
    "![serial-console](doc/serial_console.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
