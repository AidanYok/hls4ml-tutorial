{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vivado Flow\n",
    "\n",
    "We're going to train a fully connected neural network with QKeras on the jet tagging dataset and run it baremetal on Zynq-class boards (ZCU106, Ultra96, Pynq-Z1, MiniZed).\n",
    "\n",
    "## Setup\n",
    "\n",
    "Let's import the libraries, call the magic functions, and setup the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import hls4ml\n",
    "\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['PATH'] = '/extra/tools/Xilinx/Vivado/2019.1/bin:' + os.environ['PATH']\n",
    "\n",
    "def is_tool(name):\n",
    "    from distutils.spawn import find_executable\n",
    "    return find_executable(name) is not None\n",
    "\n",
    "print('-----------------------------------')\n",
    "if not is_tool('vivado_hls'):\n",
    "    print('Xilinx Vivado HLS is NOT in the PATH')\n",
    "else:\n",
    "    print('Xilinx Vivado HLS is in the PATH')\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "This is a lot like the previous notebooks, so we will go through quickly.\n",
    "\n",
    "First, we fetch the dataset from OpenML, do the normalization and make a train and test split.\n",
    "\n",
    "We save the test dataset to files so that we can use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_openml('hls4ml_lhc_jets_hlf')\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y = to_categorical(y, 5)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_val = scaler.fit_transform(X_train_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "classes = le.classes_\n",
    "\n",
    "os.makedirs('npy', exist_ok=True)\n",
    "np.save('npy/y_test.npy', y_test)\n",
    "np.save('npy/X_test.npy', X_test)\n",
    "np.save('npy/classes.npy', le.classes_, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "Our favourite 3 hidden-layer model. 6 bit quantizers everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(QDense(8, input_shape=(16,), name='fc1',\n",
    "                 kernel_quantizer=quantized_bits(6,0,alpha=1), bias_quantizer=quantized_bits(6,0,alpha=1),\n",
    "                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(QActivation(activation=quantized_relu(6), name='relu1'))\n",
    "model.add(QDense(8, name='fc2',\n",
    "                 kernel_quantizer=quantized_bits(6,0,alpha=1), bias_quantizer=quantized_bits(6,0,alpha=1),\n",
    "                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(QActivation(activation=quantized_relu(6), name='relu2'))\n",
    "model.add(QDense(8, name='fc3',\n",
    "                 kernel_quantizer=quantized_bits(6,0,alpha=1), bias_quantizer=quantized_bits(6,0,alpha=1),\n",
    "                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(QActivation(activation=quantized_relu(6), name='relu3'))\n",
    "model.add(QDense(5, name='output',\n",
    "                 kernel_quantizer=quantized_bits(6,0,alpha=1), bias_quantizer=quantized_bits(6,0,alpha=1),\n",
    "                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='softmax', name='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune\n",
    "Because why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "\n",
    "pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(0.75, begin_step=2000, frequency=100)}\n",
    "model = prune.prune_low_magnitude(model, **pruning_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "#not os.path.exists('model/KERAS_check_best_model.h5')\n",
    "if train:\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    callbacks = all_callbacks(stop_patience = 1000,\n",
    "                              lr_factor = 0.5,\n",
    "                              lr_patience = 10,\n",
    "                              lr_epsilon = 0.000001,\n",
    "                              lr_cooldown = 2,\n",
    "                              lr_minimum = 0.0000001,\n",
    "                              outputDir = 'model')\n",
    "    callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "    model.fit(X_train_val, y_train_val, batch_size=1024,\n",
    "              epochs=30, validation_split=0.25, shuffle=True,\n",
    "              callbacks = callbacks.callbacks)\n",
    "    # Save the model again but with the pruning 'stripped' to use the regular layer types\n",
    "    model = strip_pruning(model)\n",
    "    model.save('model/KERAS_check_best_model.h5')\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from qkeras.utils import _add_supported_quantized_objects\n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    model = load_model('model/KERAS_check_best_model.h5', custom_objects=co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check accuracy\n",
    "\n",
    "Do not expect a good accuracy because of the low amount of neurons. I could have done better than this, but as long as it fits both Pynq-Z1 and MiniZed, it is fine with us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotting\n",
    "\n",
    "y_keras = model.predict(X_test)\n",
    "np.save('npy/y_qkeras.npy', y_keras)\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "_ = plotting.plotMultiClassRoc(y_test, y_keras, classes)\n",
    "\n",
    "import plotting # Import local package plotting.py\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true=np.argmax(y_test, axis=1), y_pred=np.argmax(y_keras, axis=1))\n",
    "plt.figure(figsize=(9,9))\n",
    "_ = plotting.plot_confusion_matrix(cm, le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an hls4ml configuration\n",
    "Notice we're using `Strategy: Resource` for every layer, and `ReuseFactor: 64`. The Programmable Logic (FPGA part) of the Pynq-Z1 SoC is not big compared to VU9P type of parts.\n",
    "\n",
    "We also use some settings which are good for QKeras.\n",
    "\n",
    "Notice the `fpga_part:'xc7z020clg400-1'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting\n",
    "\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "hls_config['Model'] = {}\n",
    "hls_config['Model']['ReuseFactor'] = 64\n",
    "hls_config['Model']['Strategy'] = 'Resource'\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "hls_config['LayerName']['fc1']['ReuseFactor'] = 64\n",
    "hls_config['LayerName']['fc2']['ReuseFactor'] = 64\n",
    "hls_config['LayerName']['fc3']['ReuseFactor'] = 64\n",
    "hls_config['LayerName']['output']['ReuseFactor'] = 64\n",
    "hls_config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "hls_config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(hls_config)\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert and Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ZCU106\n",
    "#output_dir='hls/zcu106_prj'\n",
    "#fpga_part='xczu7ev-ffvc1156-2-e'\n",
    " \n",
    "## Ultra96\n",
    "#output_dir='hls/ultra96_prj'\n",
    "#fpga_part='xczu3eg-sbva484-1-e'\n",
    "\n",
    "## Pynq-Z1\n",
    "output_dir='hls/pynqz1_prj'\n",
    "fpga_part='xc7z020clg400-1'\n",
    "\n",
    "## MiniZed\n",
    "#output_dir='hls/minized_prj'\n",
    "#fpga_part='xc7z007sclg225-1'\n",
    "\n",
    "\n",
    "backend_config = hls4ml.converters.create_backend_config(fpga_part=fpga_part)\n",
    "backend_config['KerasModel'] = model\n",
    "backend_config['HLSConfig'] = hls_config\n",
    "backend_config['OutputDir'] = output_dir\n",
    "backend_config['Backend'] = 'Pynq'\n",
    "backend_config['Interface'] = 'm_axi' # 's_axilite' or 'm_axi'\n",
    "\n",
    "#print(\"-----------------------------------\")\n",
    "#plotting.print_dict(backend_config)\n",
    "#print(\"-----------------------------------\")\n",
    "\n",
    "hls_model = hls4ml.converters.keras_to_hls(backend_config)\n",
    "\n",
    "_ = hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually Edit the Project\n",
    "\n",
    "Similarly to the Pynq flow we can generate a project to support the Vivado flow. For the moment we manually edit the hls4ml project (from the `main` branch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Move in the `hls/BOARD_prj` where `BOARD` can be `ultra96`, `pynqz1`, `minized` etc.\n",
    "   ```\n",
    "   cd hls/BOARD_prj\n",
    "   ```\n",
    "\n",
    "1. Manually edit the file `build_prj.tcl`\n",
    "   - Set target clock period 10ns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**===== Do not go beyond here if you did not have manually edited the hls4ml project! =====**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Comparison\n",
    "\n",
    "(At this point, the C++ code that you have previously edited gets compiled and executed.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hls = hls_model.predict(np.ascontiguousarray(X_test))\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(\"Keras  Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "print(\"hls4ml Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls, axis=1))))\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable logarithmic scale on TPR and FPR axes \n",
    "logscale_tpr = False # Y axis\n",
    "logscale_fpr = False # X axis\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "_ = plotting.plotMultiClassRoc(y_test, y_keras, classes, logscale_tpr=logscale_tpr, logscale_fpr=logscale_fpr)\n",
    "plt.gca().set_prop_cycle(None) # reset the colors\n",
    "_ = plotting.plotMultiClassRoc(y_test, y_hls, classes, logscale_tpr=logscale_tpr, logscale_fpr=logscale_fpr, linestyle='--')\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "lines = [Line2D([0], [0], ls='-'),\n",
    "         Line2D([0], [0], ls='--')]\n",
    "from matplotlib.legend import Legend\n",
    "leg = Legend(ax, lines, labels=['keras', 'hls4ml'],\n",
    "            loc='lower right', frameon=False)\n",
    "_ = ax.add_artist(leg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build(csim=False,synth=True,export=True)\n",
    "\n",
    "hls4ml.report.read_vivado_report(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "See the resource usage for different boards.\n",
    "\n",
    "\n",
    "```\n",
    "+-----------------+---------+-------+--------+-------+-----+\n",
    "|                        PYNQ-Z1                           |\n",
    "+-----------------+---------+-------+--------+-------+-----+\n",
    "|Total            |        8|      7|    6089|  13557|    0|\n",
    "+-----------------+---------+-------+--------+-------+-----+\n",
    "|Available        |      280|    220|  106400|  53200|    0|\n",
    "+-----------------+---------+-------+--------+-------+-----+\n",
    "|Utilization (%)  |        2|      3|       5|     25|    0|\n",
    "+-----------------+---------+-------+--------+-------+-----+\n",
    "    +-----+-----+-----+-----+---------+\n",
    "    |  Latency  |  Interval | Pipeline|\n",
    "    | min | max | min | max |   Type  |\n",
    "    +-----+-----+-----+-----+---------+\n",
    "    |  305|  309|  305|  309|   none  |\n",
    "    +-----+-----+-----+-----+---------+\n",
    "\n",
    "\n",
    "+-----------------+---------+-------+--------+-------+----+\n",
    "|                        MiniZed                          |\n",
    "+-----------------+---------+-------+-------+-------+-----+\n",
    "|Total            |        8|      7|   6089|  13557|    0|\n",
    "+-----------------+---------+-------+-------+-------+-----+\n",
    "|Available        |      100|     66|  28800|  14400|    0|\n",
    "+-----------------+---------+-------+-------+-------+-----+\n",
    "|Utilization (%)  |        8|     10|     21|     94|    0|\n",
    "+-----------------+---------+-------+-------+-------+-----+\n",
    "    +-----+-----+-----+-----+---------+\n",
    "    |  Latency  |  Interval | Pipeline|\n",
    "    | min | max | min | max |   Type  |\n",
    "    +-----+-----+-----+-----+---------+\n",
    "    |  305|  309|  305|  309|   none  |\n",
    "    +-----+-----+-----+-----+---------+\n",
    "    \n",
    "``` \n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate .dat Files\n",
    "\n",
    "The .dat files are used\n",
    "- during the following `csim` step\n",
    "- to generate the header files for SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(output_dir + '/tb_data/tb_input_features.dat', 'w')\n",
    "for i in range(X_test.shape[0]):\n",
    "    for j in range(X_test.shape[1]):\n",
    "        f.write('{} '.format(X_test[i][j]))\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "f = open(output_dir + '/tb_data/tb_output_predictions.dat', 'w')\n",
    "for i in range(y_test.shape[0]):\n",
    "    for j in range(y_test.shape[1]):\n",
    "        f.write('{} '.format(y_test[i][j]))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Vivado HLS csim\n",
    "\n",
    "Move in the `hls/BOARD_prj` where `BOARD` can be `ultra96`, `pynqz1`, `minized` etc. and run Vivado HLS.\n",
    "```\n",
    "cd hls/BOARD_prj\n",
    "vivado_hls -p myproject_prj\n",
    "```\n",
    "\n",
    "Run C-sim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate IP in a Vivado Project\n",
    "\n",
    "Move to the directory `sys` for the next steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
