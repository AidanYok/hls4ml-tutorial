Backend: Vivado
ClockPeriod: 10
HLSConfig:
  LayerName:
    batch_normalization:
      Precision:
        bias: ap_fixed<16,6>
        scale: ap_fixed<16,6>
      ReuseFactor: 512
    batch_normalization_1:
      Precision:
        bias: ap_fixed<16,6>
        scale: ap_fixed<16,6>
      ReuseFactor: 512
    batch_normalization_2:
      Precision:
        bias: ap_fixed<16,6>
        scale: ap_fixed<16,6>
      ReuseFactor: 512
    batch_normalization_3:
      Precision:
        bias: ap_fixed<16,6>
        scale: ap_fixed<16,6>
      ReuseFactor: 512
    batch_normalization_4:
      Precision:
        bias: ap_fixed<16,6>
        scale: ap_fixed<16,6>
      ReuseFactor: 512
    batch_normalization_5:
      Precision:
        bias: ap_fixed<16,6>
        scale: ap_fixed<16,6>
      ReuseFactor: 512
    batch_normalization_6:
      Precision:
        bias: ap_fixed<16,6>
        scale: ap_fixed<16,6>
      ReuseFactor: 512
    batch_normalization_7:
      Precision:
        bias: ap_fixed<16,6>
        scale: ap_fixed<16,6>
      ReuseFactor: 512
    batch_normalization_8:
      Precision:
        bias: ap_fixed<16,6>
        scale: ap_fixed<16,6>
      ReuseFactor: 512
    input_1:
      Precision: ap_fixed<8,8>
    q_activation:
      Precision:
        result: ap_fixed<7,4>
      ReuseFactor: 512
    q_activation_1:
      Precision:
        result: ap_fixed<7,4>
      ReuseFactor: 512
    q_activation_2:
      Precision:
        result: ap_fixed<7,4>
      ReuseFactor: 512
    q_activation_3:
      Precision:
        result: ap_fixed<7,4>
      ReuseFactor: 512
    q_activation_4:
      Precision:
        result: ap_fixed<7,4>
      ReuseFactor: 512
    q_activation_5:
      Precision:
        result: ap_fixed<7,4>
      ReuseFactor: 512
    q_activation_6:
      Precision:
        result: ap_fixed<7,4>
      ReuseFactor: 512
    q_activation_7:
      Precision:
        result: ap_fixed<7,4>
      ReuseFactor: 512
    q_activation_8:
      Precision:
        result: ap_fixed<7,4>
      ReuseFactor: 512
    q_dense:
      Precision:
        bias: ap_fixed<7,1>
        weight: ap_fixed<7,1>
      ReuseFactor: 512
    q_dense_1:
      Precision:
        bias: ap_fixed<7,1>
        weight: ap_fixed<7,1>
      ReuseFactor: 512
    q_dense_2:
      Precision:
        bias: ap_fixed<7,1>
        weight: ap_fixed<7,1>
      ReuseFactor: 512
    q_dense_3:
      Precision:
        bias: ap_fixed<7,1>
        weight: ap_fixed<7,1>
      ReuseFactor: 512
    q_dense_4:
      Precision:
        bias: ap_fixed<7,1>
        weight: ap_fixed<7,1>
      ReuseFactor: 512
    q_dense_5:
      Precision:
        bias: ap_fixed<7,1>
        weight: ap_fixed<7,1>
      ReuseFactor: 512
    q_dense_6:
      Precision:
        bias: ap_fixed<7,1>
        weight: ap_fixed<7,1>
      ReuseFactor: 512
    q_dense_7:
      Precision:
        bias: ap_fixed<7,1>
        weight: ap_fixed<7,1>
      ReuseFactor: 512
    q_dense_8:
      Precision:
        bias: ap_fixed<7,1>
        weight: ap_fixed<7,1>
      ReuseFactor: 512
    q_dense_9:
      Precision:
        bias: ap_fixed<7,7>
        weight: ap_fixed<7,7>
      ReuseFactor: 512
  Model:
    Precision: ap_fixed<32,16>
    ReuseFactor: 512
    Strategy: Resource
IOType: io_parallel
KerasModel: !keras_model 'hls/precision_lut_scaling_master_branch/train_config_bits_6_frames_4_mels_64_encDims_8_hidDims_64_bn_True_l1reg_0/anomaly_detector_pynqz2_m_axi_16_serial_reuse_512_prj/keras_model.h5'
OutputDir: hls/precision_lut_scaling_master_branch/train_config_bits_6_frames_4_mels_64_encDims_8_hidDims_64_bn_True_l1reg_0/anomaly_detector_pynqz2_m_axi_16_serial_reuse_512_prj
ProjectName: anomaly_detector
Stamp: 14dBcf30
XilinxPart: xc7z020clg400-1
